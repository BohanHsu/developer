from collections import deque

class DecisionTree:

    def __init__(self, training_set, attr_selector):
        self.training_data = [x[:-1] for x in training_set]
        self.classes = [x[-1] for x in training_set]
        self.attr_selector = attr_selector
        self.root = None
        self.queue = deque([])
        self.build_tree()
    
    def build_tree(self):
        root = Node()
        root.left_data_index = range(0, len(self.training_data))
        root.attributes_left = range(0, len(self.training_data[0]))
        self.root = root
        self.queue.append(root)

        while self.queue:
            n = self.queue.popleft()
            self.split_node(n)

    def split_node(self, node):
        if not node.attributes_left:
            # what's the class?
            counts = {}
            for i in node.left_data_index:
                value = self.classes[i]
                if not value in counts:
                    counts[value] = 0

                counts[value] = counts[value] + 1

            max = float('-inf')
            node_cls = 'unknown1'

            for k in counts:
                v = counts[k]
                if v > max:
                    max = v
                    node_cls = k

            node.cls = node_cls

        elif not node.left_data_index:
            # there is no data left but still attributes
            node.cls = 'unknown2'
        else:
            train_data = []
            cls_data = []
            for i in node.left_data_index:
                train_data.append(self.training_data[i])
                cls_data.append(self.classes[i])

            #print 'train_data', train_data
            #print 'cls_data', cls_data

            selected_attrubte_index = self.attr_selector(train_data, cls_data, node.attributes_left)
            node.selected_attribute = selected_attrubte_index
            node.attributes_left.remove(selected_attrubte_index)

            for value in set([x[selected_attrubte_index] for x in train_data]):
                n = Node()
                n.attributes_left = list(node.attributes_left)
                n.parent_node = node
                node.posterities[value] = n
                data_after_filter = []
                for i in node.left_data_index:
                    if self.training_data[i][node.selected_attribute] == value:
                        data_after_filter.append(i)

                n.left_data_index = data_after_filter
                self.queue.append(n)

    def prune_node(self, node, prune_set):
        # first vote the node
        counts = {}
        for i in node.left_data_index:
            cls = self.classes[i]
            if not cls in counts:
                counts[cls] = 0

            counts[cls] = counts[cls] + 1

        max = float('-inf')
        max_k = None
        for k in counts:
            v = counts[k]
            if v > max:
                max = v
                max_k = k
                
        # max is the majority vote

    def make_decision(self, data_tuple, node):
        cls = node.cls
        while not cls:
            attribute_value = data_tuple[node.selected_attribute]
            succeed_node = self.posterities[attribute_value]
            cls = succeed_node.cls

        return cls

class Node:
    def __init__(self):
        self.parent_node = None
        self.selected_attribute = None
        self.attribute_type = None
        # index of lefted attributes
        self.attributes_left = None
        # if is numerical:
        self.split_value = None
        self.posterities = {}
        #if is a leaf node
        self.cls = None
        self.left_data_index = None
